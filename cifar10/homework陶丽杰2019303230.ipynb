{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CTFAR-10\n",
    "本次作业为CIFAR-10数据分类的程序设计问题。作业均采用Pytorch软件和Jupyter notebook 软件完成，上交文件命名为Homework2_姓名_学号.ipynb。助教会运行3次代码，取三次分类精度最高值为模型的最后精度，最后分类精度到达95%即完成。作业详细描述如下：\n",
    "数据在共享文件Cifar10Dataset文件夹下，data_batch_1--data_batch_5文件为50000张训练样本图片，test_batch文件为10000张测试样本图片，更加详细的说明文档见数据包中的readme.html。建立Homework2_姓名_学号.ipynb文件，采用PyTorch中torchvision包的datasets.CIFAR10和torch.utils.data.DataLoader函数进行数据集读取。采用深度学习模型进行分类，模型中至少包括3层神经网络，分类精度依据测试集的表现为准。\n",
    "完成的作业打包成压缩包，命名为”学号_姓名_学院_班级”，发送至邮箱1004848808@qq.com,作业提交时间：2022年1月7日 24:00。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 进行深度学习\n",
    "这里是使用resnet模型"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        #这里的即为两个3*3 conv\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),      #bias为偏置，False表示不添加偏置\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        self.shortcut = nn.Sequential() #shortcut connections\n",
    "        if stride != 1 or inchannel != outchannel: #判断入通道和出通道是否一样，不一样的话进行卷积操作\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(outchannel)\n",
    "            )\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResidualBlock):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        #图片处理，也就是白色方框内的3*3 conv\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        #中间的残差网络部分，与图上的结构一一对应\n",
    "        self.layer1 = self.make_layer(ResidualBlock, 64, 64, 2, stride=1)\n",
    "        self.layer2 = self.make_layer(ResidualBlock, 64, 128, 2, stride=2)\n",
    "        self.layer3 = self.make_layer(ResidualBlock, 128, 256, 2, stride=2)\n",
    "        self.layer4 = self.make_layer(ResidualBlock, 256, 512, 2, stride=2)\n",
    "        self.avg_pool2d = nn.AvgPool2d(4)\n",
    "        self.fc = nn.Linear(512, 10)\n",
    "\n",
    "    #相当于看处理几次，18的是每个处理两次\n",
    "    def make_layer(self, block, inchannel, outchannel, num_blocks, stride):\n",
    "        layers = []\n",
    "        for i in range(1, num_blocks):\n",
    "            layers.append(block(inchannel, outchannel, stride))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avg_pool2d(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "def ResNet_cifar():\n",
    "    return ResNet(ResidualBlock)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "#from resnet import ResNet_cifar\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "num_epoch = 10\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "\n",
    "#MNIST数据集加载\n",
    "\n",
    "train_dataset = datasets.CIFAR10(\n",
    "    root= './data',\n",
    "    train= True, \n",
    "    transform= transform, \n",
    "    download= True\n",
    ")\n",
    "train_loader = data.DataLoader(\n",
    "    dataset= train_dataset, \n",
    "    batch_size= BATCH_SIZE, \n",
    "    shuffle= True\n",
    ")\n",
    "test_dataset = datasets.CIFAR10(\n",
    "    root= './data', \n",
    "    train= False,\n",
    "    transform= transform,\n",
    "    download= True\n",
    ")\n",
    "test_loader = data.DataLoader(\n",
    "    dataset= test_dataset, \n",
    "    batch_size= BATCH_SIZE, \n",
    "    shuffle= True\n",
    ")\n",
    "\n",
    "#定义网络\n",
    "net = ResNet_cifar()\n",
    "print(net)\n",
    "\n",
    "#进行优化\n",
    "#optimizer = torch.optim.RMSprop(net_cifar10.parameters(), lr = 0.005, alpha= 0.9)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.001, betas= (0.9, 0.99))\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    print('epoch = %d' % epoch)\n",
    "    for i, (image, label) in enumerate(train_loader):\n",
    "\n",
    "        x = net(image)\n",
    "        loss = loss_function(x, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print('loss = %.5f' % loss)\n",
    "\n",
    "#对测试集的评估\n",
    "total = 0\n",
    "correct = 0\n",
    "net.eval()\n",
    "\n",
    "for image, label in test_loader:\n",
    "    x = net(image)\n",
    "    _, prediction = torch.max(x, 1)\n",
    "    total += label.size(0)\n",
    "    correct += (prediction == label).sum()\n",
    "print('There are ' + str(correct.item()) + ' correct pictures.')\n",
    "print('Accuracy=%.2f' % (100.00 * correct.item() / total))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using downloaded and verified file: ./data/cifar-10-python.tar.gz\n",
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "ResNet(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (left): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (left): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (left): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (left): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (avg_pool2d): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "epoch = 0\n",
      "loss = 2.37940\n",
      "loss = 1.84124\n",
      "loss = 1.73163\n",
      "loss = 1.88817\n",
      "loss = 1.74614\n",
      "loss = 1.80234\n",
      "loss = 1.40719\n",
      "loss = 1.52463\n",
      "loss = 1.15813\n",
      "loss = 1.29803\n",
      "loss = 1.12698\n",
      "loss = 1.65143\n",
      "loss = 0.85989\n",
      "loss = 1.57780\n",
      "loss = 1.50051\n",
      "loss = 1.33342\n",
      "loss = 1.18582\n",
      "loss = 1.20659\n",
      "loss = 1.05824\n",
      "loss = 0.88643\n",
      "loss = 1.43334\n",
      "loss = 1.10267\n",
      "loss = 0.80416\n",
      "loss = 1.18284\n",
      "loss = 0.31945\n",
      "epoch = 1\n",
      "loss = 0.64582\n",
      "loss = 0.90189\n",
      "loss = 0.89364\n",
      "loss = 1.29727\n",
      "loss = 0.69369\n",
      "loss = 1.12675\n",
      "loss = 1.60967\n",
      "loss = 0.95111\n",
      "loss = 1.43316\n",
      "loss = 0.60796\n",
      "loss = 0.82065\n",
      "loss = 0.71428\n",
      "loss = 1.00037\n",
      "loss = 0.93798\n",
      "loss = 0.69760\n",
      "loss = 1.14941\n",
      "loss = 1.13882\n",
      "loss = 1.02095\n",
      "loss = 0.80980\n",
      "loss = 0.75406\n",
      "loss = 1.18953\n",
      "loss = 0.56268\n",
      "loss = 0.63321\n",
      "loss = 0.76066\n",
      "loss = 0.35091\n",
      "epoch = 2\n",
      "loss = 0.62295\n",
      "loss = 0.59679\n",
      "loss = 0.91721\n",
      "loss = 0.65676\n",
      "loss = 0.52022\n",
      "loss = 0.65160\n",
      "loss = 0.51008\n",
      "loss = 0.46119\n",
      "loss = 0.63812\n",
      "loss = 0.35861\n",
      "loss = 0.44847\n",
      "loss = 0.63290\n",
      "loss = 0.85926\n",
      "loss = 0.49629\n",
      "loss = 0.82826\n",
      "loss = 0.49971\n",
      "loss = 0.68582\n",
      "loss = 0.56156\n",
      "loss = 0.68086\n",
      "loss = 0.80707\n",
      "loss = 0.67922\n",
      "loss = 0.50570\n",
      "loss = 0.73850\n",
      "loss = 0.95620\n",
      "loss = 0.78047\n",
      "epoch = 3\n",
      "loss = 0.58899\n",
      "loss = 0.76896\n",
      "loss = 0.82871\n",
      "loss = 0.22701\n",
      "loss = 0.83481\n",
      "loss = 0.46955\n",
      "loss = 0.69925\n",
      "loss = 0.38597\n",
      "loss = 0.52654\n",
      "loss = 0.86043\n",
      "loss = 0.26790\n",
      "loss = 0.29448\n",
      "loss = 0.46734\n",
      "loss = 0.26473\n",
      "loss = 0.31221\n",
      "loss = 0.51718\n",
      "loss = 0.37313\n",
      "loss = 0.43374\n",
      "loss = 0.43246\n",
      "loss = 0.59668\n",
      "loss = 0.79316\n",
      "loss = 0.50011\n",
      "loss = 0.29732\n",
      "loss = 0.41950\n",
      "loss = 0.37584\n",
      "epoch = 4\n",
      "loss = 0.33192\n",
      "loss = 0.12316\n",
      "loss = 0.57367\n",
      "loss = 0.10319\n",
      "loss = 0.55873\n",
      "loss = 0.20078\n",
      "loss = 0.34250\n",
      "loss = 0.31754\n",
      "loss = 0.47993\n",
      "loss = 0.54066\n",
      "loss = 0.29870\n",
      "loss = 0.50757\n",
      "loss = 0.44342\n",
      "loss = 0.70710\n",
      "loss = 0.27497\n",
      "loss = 0.78274\n",
      "loss = 0.07666\n",
      "loss = 0.40526\n",
      "loss = 0.23138\n",
      "loss = 0.46399\n",
      "loss = 0.55328\n",
      "loss = 0.35047\n",
      "loss = 0.37095\n",
      "loss = 0.26059\n",
      "loss = 0.18611\n",
      "epoch = 5\n",
      "loss = 0.12582\n",
      "loss = 0.28183\n",
      "loss = 0.15423\n",
      "loss = 0.11875\n",
      "loss = 0.11466\n",
      "loss = 0.37792\n",
      "loss = 0.41419\n",
      "loss = 0.25963\n",
      "loss = 0.29512\n",
      "loss = 0.06449\n",
      "loss = 0.08145\n",
      "loss = 0.22126\n",
      "loss = 0.21028\n",
      "loss = 0.42248\n",
      "loss = 0.15490\n",
      "loss = 0.26497\n",
      "loss = 0.30431\n",
      "loss = 0.13440\n",
      "loss = 0.44308\n",
      "loss = 0.25833\n",
      "loss = 0.35853\n",
      "loss = 0.16154\n",
      "loss = 0.19291\n",
      "loss = 0.23578\n",
      "loss = 0.22056\n",
      "epoch = 6\n",
      "loss = 0.25428\n",
      "loss = 0.10145\n",
      "loss = 0.07121\n",
      "loss = 0.04262\n",
      "loss = 0.08686\n",
      "loss = 0.05805\n",
      "loss = 0.14382\n",
      "loss = 0.06600\n",
      "loss = 0.03969\n",
      "loss = 0.05122\n",
      "loss = 0.09180\n",
      "loss = 0.37024\n",
      "loss = 0.06869\n",
      "loss = 0.08602\n",
      "loss = 0.18867\n",
      "loss = 0.03718\n",
      "loss = 0.06763\n",
      "loss = 0.09213\n",
      "loss = 0.12886\n",
      "loss = 0.25956\n",
      "loss = 0.05771\n",
      "loss = 0.33636\n",
      "loss = 0.12436\n",
      "loss = 0.26441\n",
      "loss = 0.14039\n",
      "epoch = 7\n",
      "loss = 0.22766\n",
      "loss = 0.16431\n",
      "loss = 0.20229\n",
      "loss = 0.54978\n",
      "loss = 0.37319\n",
      "loss = 0.19674\n",
      "loss = 0.06148\n",
      "loss = 0.20870\n",
      "loss = 0.18091\n",
      "loss = 0.13900\n",
      "loss = 0.02485\n",
      "loss = 0.27199\n",
      "loss = 0.15875\n",
      "loss = 0.16852\n",
      "loss = 0.07052\n",
      "loss = 0.00865\n",
      "loss = 0.00754\n",
      "loss = 0.10673\n",
      "loss = 0.48018\n",
      "loss = 0.15856\n",
      "loss = 0.33582\n",
      "loss = 0.25589\n",
      "loss = 0.08618\n",
      "loss = 0.00549\n",
      "loss = 0.10565\n",
      "epoch = 8\n",
      "loss = 0.11196\n",
      "loss = 0.03095\n",
      "loss = 0.09803\n",
      "loss = 0.02766\n",
      "loss = 0.04537\n",
      "loss = 0.09230\n",
      "loss = 0.06618\n",
      "loss = 0.02143\n",
      "loss = 0.06394\n",
      "loss = 0.03811\n",
      "loss = 0.23636\n",
      "loss = 0.02774\n",
      "loss = 0.17791\n",
      "loss = 0.46450\n",
      "loss = 0.00424\n",
      "loss = 0.05334\n",
      "loss = 0.21844\n",
      "loss = 0.10342\n",
      "loss = 0.03722\n",
      "loss = 0.00940\n",
      "loss = 0.01537\n",
      "loss = 0.01944\n",
      "loss = 0.01166\n",
      "loss = 0.17455\n",
      "loss = 0.11922\n",
      "epoch = 9\n",
      "loss = 0.05979\n",
      "loss = 0.03094\n",
      "loss = 0.05214\n",
      "loss = 0.06066\n",
      "loss = 0.12823\n",
      "loss = 0.04720\n",
      "loss = 0.00696\n",
      "loss = 0.03893\n",
      "loss = 0.03548\n",
      "loss = 0.01382\n",
      "loss = 0.01554\n",
      "loss = 0.40091\n",
      "loss = 0.16814\n",
      "loss = 0.16216\n",
      "loss = 0.16204\n",
      "loss = 0.12701\n",
      "loss = 0.19468\n",
      "loss = 0.03538\n",
      "loss = 0.00267\n",
      "loss = 0.00613\n",
      "loss = 0.04705\n",
      "loss = 0.28065\n",
      "loss = 0.05758\n",
      "loss = 0.01795\n",
      "loss = 0.16769\n",
      "There are 8262 correct pictures.\n",
      "Accuracy=82.62\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 结果\n",
    "最终的精度为**82.62**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 遇到的困难及解决方法\n",
    "* **数据输入的万般尝试**\n",
    "\n",
    "**问题**：\n",
    "* 存在官网下载慢容易卡的问题，总是下载失败\n",
    "\n",
    "**解决尝试**：\n",
    "1. 本地下载数据，解压数据，企图使用numpy读取数据以替代torchvision的读取：\n",
    "\n",
    "```Python\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# cifar10数据导入函数\n",
    "\n",
    "# 对每一个batch进行导入\n",
    "def load_batch(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:                                         # 打开文件\n",
    "        d = pickle.load(fo, encoding='bytes')                            # 导入文件，以bytes编码格式\n",
    "        d_decoded = {}                                                   # 定义字典\n",
    "        for k, v in d.items():                                           # 对数据集中的特征与标签遍历\n",
    "            d_decoded[k.decode('utf8')] = v                              # 用数据集填充d_decoded\n",
    "        d = d_decoded\n",
    "        data = d['data']                                                 # 读出batch中所有特征存入data\n",
    "        labels = d['labels']                                             # 读出batch中所有标签存入labels\n",
    "        data = data.reshape(data.shape[0], 3, 32, 32)                    # 数组形变 \n",
    "    return data, labels                                                  # 返回最原始的特征与标签   \n",
    "\n",
    "def load_data(path ='cifar-10-batches-py'):\n",
    "    \"\"\"Loads CIFAR10 dataset.\n",
    "    # Returns\n",
    "        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 训练集训练数据数量\n",
    "    num_train_samples = 50000\n",
    "    \n",
    "    # 新建数组变量，根据数据集情况建立，50000张3通道的32*32的图片\n",
    "    x_train = np.empty((num_train_samples, 3, 32, 32), dtype='uint8')\n",
    "    y_train = np.empty((num_train_samples,), dtype='uint8')\n",
    "\n",
    "    # 这里一共有5组data_batch，1到5循环遍历，每一个batch有10000张图片，导入图片\n",
    "    for i in range(1, 6):\n",
    "        fpath = os.path.join(path, 'data_batch_' + str(i))          # 根据文件夹进行绝对地址访问\n",
    "        (x_train[(i - 1) * 10000: i * 10000, :, :, :],              #1-10000，10001-20000，20001-30000 等等    3通道32*32的彩色图\n",
    "         y_train[(i - 1) * 10000: i * 10000]) = load_batch(fpath)\n",
    "        \n",
    "    fpath = os.path.join(path, 'test_batch')\n",
    "    x_test, y_test = load_batch(fpath)\n",
    "\n",
    "    y_train = np.reshape(y_train, (len(y_train), 1))   # 增加一维,相当于把行向量变成列向量\n",
    "    y_test = np.reshape(y_test, (len(y_test), 1))\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_data('cifar-10-batches-py')\n",
    "\n",
    "classes = ('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')\n",
    "\n",
    "x_test=x_test.transpose(0,2,3,1).astype(\"float\")# 将3,32，32类型的数据转化为（32，32，3）\n",
    "x_train=x_train.transpose(0,2,3,1).astype(\"float\")\n",
    "\n",
    "```\n",
    "\n",
    "<img src=\"1.png\" />\n",
    "\n",
    "之后进行过将train_dataset，test_dataset构造tensor类型的元组的尝试……均以失败告终\n",
    "\n",
    "2. 本地下载数据，更改root\n",
    "   尝试过修改相对路径，更改文件名称等，均以在文件中找不到对应文件报错告终\n",
    "\n",
    "**解决方法**：\n",
    "\n",
    "参考连接：https://www.freesion.com/article/5198895969/\n",
    "\n",
    "思路：下载本地数据，最后更改cifar.py文件中的url,使得“下载”直接从本地开始下载，即直接从本地进行导入\n",
    "\n",
    "<img src=\"2.png\" />\n",
    "\n",
    "最后成功导入数据，进行后面的操作\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('forpylearn': conda)"
  },
  "interpreter": {
   "hash": "389f2cfaf66ee98cefd6c178d5ac88972932bfe61afe46bb81b3bd8a45be44af"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}